{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header-section",
            "metadata": {},
            "source": [
                "# PyTorch æ•°æ®å¢å¼º (Data Augmentation) å®Œæ•´æ•™ç¨‹\n",
                "\n",
                "æœ¬æ•™ç¨‹æ¶µç›–å¸¸ç”¨çš„å›¾åƒå˜æ¢æ“ä½œï¼ŒåŒ…æ‹¬ï¼š\n",
                "- åŸºç¡€å˜æ¢ï¼šToTensor, Normalize, Resize\n",
                "- è£å‰ªæ“ä½œï¼šRandomCrop, CenterCrop\n",
                "- ç¿»è½¬æ“ä½œï¼šRandomHorizontalFlip, RandomVerticalFlip\n",
                "- æ—‹è½¬æ“ä½œï¼šRandomRotation\n",
                "- é¢œè‰²å¢å¼ºï¼šColorJitter, RandomGrayscale\n",
                "- ç»„åˆå˜æ¢ï¼šCompose\n",
                "\n",
                "**å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡å¦‚ä½•ä½¿ç”¨ torchvision.transforms è¿›è¡Œæ•°æ®å¢å¼º"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "import-section",
            "metadata": {},
            "source": [
                "## 1. å¯¼å…¥å¿…è¦çš„åº“"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import cv2\n",
                "import os\n",
                "import numpy as np\n",
                "from PIL import Image  # PIL æ˜¯ torchvision.transforms æ¨èä½¿ç”¨çš„å›¾åƒæ ¼å¼\n",
                "import matplotlib.pyplot as plt\n",
                "from torchvision import transforms\n",
                "from torch.utils.tensorboard import SummaryWriter\n",
                "\n",
                "# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å… matplotlib æ˜¾ç¤ºä¸­æ–‡æ—¶å‡ºç°ä¹±ç ï¼‰\n",
                "plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨é»‘ä½“æ˜¾ç¤ºä¸­æ–‡\n",
                "plt.rcParams['axes.unicode_minus'] = False    # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·\n",
                "\n",
                "print(\"âœ… åº“å¯¼å…¥æˆåŠŸï¼\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load-image-section",
            "metadata": {},
            "source": [
                "## 2. è¯»å–æµ‹è¯•å›¾ç‰‡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load-image",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰å›¾åƒè·¯å¾„\n",
                "img_path = r'data\\train\\ants_image\\5650366_e22b7e1065.jpg'\n",
                "\n",
                "# ä½¿ç”¨ PIL è¯»å–å›¾ç‰‡ï¼ˆæ¨èæ–¹å¼ï¼Œå› ä¸º torchvision.transforms é»˜è®¤æ”¯æŒ PILï¼‰\n",
                "img_pil = Image.open(img_path)\n",
                "\n",
                "# ä¹Ÿå¯ä»¥ç”¨ OpenCV è¯»å–ï¼Œä½†éœ€è¦è½¬æ¢\n",
                "img_cv = cv2.imread(img_path)\n",
                "img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "# æ˜¾ç¤ºåŸå§‹å›¾ç‰‡ä¿¡æ¯\n",
                "print(f\"PIL å›¾ç‰‡å°ºå¯¸: {img_pil.size}\")  # (å®½, é«˜)\n",
                "print(f\"OpenCV å›¾ç‰‡å½¢çŠ¶: {img_cv.shape}\")  # (é«˜, å®½, é€šé“)\n",
                "\n",
                "# æ˜¾ç¤ºåŸå§‹å›¾ç‰‡\n",
                "plt.figure(figsize=(6, 6))\n",
                "plt.imshow(img_pil)\n",
                "plt.title(\"åŸå§‹å›¾ç‰‡\")\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "basic-transforms-section",
            "metadata": {},
            "source": [
                "## 3. åŸºç¡€å˜æ¢\n",
                "\n",
                "### 3.1 ToTensor - è½¬æ¢ä¸ºå¼ é‡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "to-tensor",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®ä¾‹åŒ– ToTensor å·¥å…·\n",
                "to_tensor = transforms.ToTensor()\n",
                "\n",
                "# æ‰§è¡Œè½¬æ¢\n",
                "# 1. ç»´åº¦è½¬æ¢ï¼š(H, W, C) -> (C, H, W)\n",
                "# 2. å½’ä¸€åŒ–ï¼š[0, 255] -> [0.0, 1.0]\n",
                "# 3. æ•°æ®ç±»å‹ï¼šuint8 -> float32\n",
                "tensor_img = to_tensor(img_pil)\n",
                "\n",
                "print(f\"Tensor å½¢çŠ¶: {tensor_img.shape}\")  # torch.Size([C, H, W])\n",
                "print(f\"Tensor æ•°æ®ç±»å‹: {tensor_img.dtype}\")\n",
                "print(f\"Tensor æ•°å€¼èŒƒå›´: [{tensor_img.min():.3f}, {tensor_img.max():.3f}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "normalize-section",
            "metadata": {},
            "source": [
                "### 3.2 Normalize - æ ‡å‡†åŒ–\n",
                "\n",
                "å…¬å¼ï¼š`output = (input - mean) / std`\n",
                "\n",
                "å¸¸ç”¨å‚æ•°ï¼ˆImageNet é¢„è®­ç»ƒæ¨¡å‹ï¼‰ï¼š\n",
                "- mean = [0.485, 0.456, 0.406]  # RGB ä¸‰é€šé“çš„å‡å€¼\n",
                "- std = [0.229, 0.224, 0.225]   # RGB ä¸‰é€šé“çš„æ ‡å‡†å·®"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "normalize",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰æ ‡å‡†åŒ–æ“ä½œ\n",
                "normalize = transforms.Normalize(\n",
                "    mean=[0.485, 0.456, 0.406],  # ImageNet æ•°æ®é›†çš„å‡å€¼\n",
                "    std=[0.229, 0.224, 0.225]    # ImageNet æ•°æ®é›†çš„æ ‡å‡†å·®\n",
                ")\n",
                "\n",
                "# å…ˆè½¬ä¸º Tensorï¼Œå†æ ‡å‡†åŒ–\n",
                "normalized_img = normalize(tensor_img)\n",
                "\n",
                "print(f\"æ ‡å‡†åŒ–åçš„æ•°å€¼èŒƒå›´: [{normalized_img.min():.3f}, {normalized_img.max():.3f}]\")\n",
                "print(\"âš ï¸ æ³¨æ„ï¼šæ ‡å‡†åŒ–åçš„å›¾ç‰‡ä¸èƒ½ç›´æ¥æ˜¾ç¤ºï¼Œå› ä¸ºåƒç´ å€¼å¯èƒ½ä¸ºè´Ÿæ•°\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "resize-section",
            "metadata": {},
            "source": [
                "### 3.3 Resize - è°ƒæ•´å¤§å°"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "resize",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰è°ƒæ•´å¤§å°æ“ä½œ\n",
                "resize = transforms.Resize((256, 256))  # (é«˜, å®½)\n",
                "\n",
                "# å¯¹ PIL å›¾ç‰‡è¿›è¡Œç¼©æ”¾\n",
                "resized_img = resize(img_pil)\n",
                "\n",
                "print(f\"åŸå§‹å°ºå¯¸: {img_pil.size}\")\n",
                "print(f\"è°ƒæ•´åå°ºå¯¸: {resized_img.size}\")\n",
                "\n",
                "# æ˜¾ç¤ºå¯¹æ¯”\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
                "axes[0].imshow(img_pil)\n",
                "axes[0].set_title(f\"åŸå§‹å›¾ç‰‡ {img_pil.size}\")\n",
                "axes[0].axis('off')\n",
                "\n",
                "axes[1].imshow(resized_img)\n",
                "axes[1].set_title(f\"Resize å {resized_img.size}\")\n",
                "axes[1].axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "crop-section",
            "metadata": {},
            "source": [
                "## 4. è£å‰ªæ“ä½œ\n",
                "\n",
                "### 4.1 RandomCrop - éšæœºè£å‰ª"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "random-crop",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰éšæœºè£å‰ªï¼ˆæ¯æ¬¡è¿è¡Œç»“æœä¸åŒï¼‰\n",
                "random_crop = transforms.RandomCrop((200, 200))  # è£å‰ªæˆ 200x200\n",
                "\n",
                "# å¤šæ¬¡è£å‰ªï¼Œè§‚å¯Ÿéšæœºæ€§\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i in range(6):\n",
                "    cropped_img = random_crop(img_pil)\n",
                "    axes[i].imshow(cropped_img)\n",
                "    axes[i].set_title(f\"éšæœºè£å‰ª #{i+1}\")\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle(\"RandomCrop - æ¯æ¬¡è£å‰ªä½ç½®ä¸åŒ\", fontsize=16)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "center-crop-section",
            "metadata": {},
            "source": [
                "### 4.2 CenterCrop - ä¸­å¿ƒè£å‰ª"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "center-crop",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰ä¸­å¿ƒè£å‰ªï¼ˆæ€»æ˜¯ä»ä¸­å¿ƒè£å‰ªï¼Œç»“æœå›ºå®šï¼‰\n",
                "center_crop = transforms.CenterCrop((200, 200))\n",
                "\n",
                "# æ‰§è¡Œä¸­å¿ƒè£å‰ª\n",
                "center_cropped_img = center_crop(img_pil)\n",
                "\n",
                "# æ˜¾ç¤ºå¯¹æ¯”\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
                "axes[0].imshow(img_pil)\n",
                "axes[0].set_title(\"åŸå§‹å›¾ç‰‡\")\n",
                "axes[0].axis('off')\n",
                "\n",
                "axes[1].imshow(center_cropped_img)\n",
                "axes[1].set_title(\"CenterCrop - ä»ä¸­å¿ƒè£å‰ª\")\n",
                "axes[1].axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "flip-section",
            "metadata": {},
            "source": [
                "## 5. ç¿»è½¬æ“ä½œ\n",
                "\n",
                "### 5.1 RandomHorizontalFlip - éšæœºæ°´å¹³ç¿»è½¬"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "horizontal-flip",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰éšæœºæ°´å¹³ç¿»è½¬ï¼ˆp=0.5 è¡¨ç¤ºæœ‰ 50% çš„æ¦‚ç‡ç¿»è½¬ï¼‰\n",
                "h_flip = transforms.RandomHorizontalFlip(p=1.0)  # p=1.0 è¡¨ç¤ºå¿…å®šç¿»è½¬ï¼ˆä¸ºäº†æ¼”ç¤ºï¼‰\n",
                "\n",
                "# æ‰§è¡Œæ°´å¹³ç¿»è½¬\n",
                "h_flipped_img = h_flip(img_pil)\n",
                "\n",
                "# æ˜¾ç¤ºå¯¹æ¯”\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
                "axes[0].imshow(img_pil)\n",
                "axes[0].set_title(\"åŸå§‹å›¾ç‰‡\")\n",
                "axes[0].axis('off')\n",
                "\n",
                "axes[1].imshow(h_flipped_img)\n",
                "axes[1].set_title(\"æ°´å¹³ç¿»è½¬\")\n",
                "axes[1].axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vertical-flip-section",
            "metadata": {},
            "source": [
                "### 5.2 RandomVerticalFlip - éšæœºå‚ç›´ç¿»è½¬"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "vertical-flip",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰éšæœºå‚ç›´ç¿»è½¬\n",
                "v_flip = transforms.RandomVerticalFlip(p=1.0)\n",
                "\n",
                "# æ‰§è¡Œå‚ç›´ç¿»è½¬\n",
                "v_flipped_img = v_flip(img_pil)\n",
                "\n",
                "# æ˜¾ç¤ºå¯¹æ¯”\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
                "axes[0].imshow(img_pil)\n",
                "axes[0].set_title(\"åŸå§‹å›¾ç‰‡\")\n",
                "axes[0].axis('off')\n",
                "\n",
                "axes[1].imshow(v_flipped_img)\n",
                "axes[1].set_title(\"å‚ç›´ç¿»è½¬\")\n",
                "axes[1].axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "rotation-section",
            "metadata": {},
            "source": [
                "## 6. æ—‹è½¬æ“ä½œ\n",
                "\n",
                "### 6.1 RandomRotation - éšæœºæ—‹è½¬"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "random-rotation",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰éšæœºæ—‹è½¬ï¼ˆdegrees å‚æ•°æŒ‡å®šæ—‹è½¬è§’åº¦èŒƒå›´ï¼‰\n",
                "rotation = transforms.RandomRotation(degrees=45)  # åœ¨ [-45Â°, 45Â°] ä¹‹é—´éšæœºæ—‹è½¬\n",
                "\n",
                "# å¤šæ¬¡æ—‹è½¬ï¼Œè§‚å¯Ÿéšæœºæ€§\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i in range(6):\n",
                "    rotated_img = rotation(img_pil)\n",
                "    axes[i].imshow(rotated_img)\n",
                "    axes[i].set_title(f\"éšæœºæ—‹è½¬ #{i+1}\")\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle(\"RandomRotation - æ¯æ¬¡æ—‹è½¬è§’åº¦ä¸åŒ (Â±45Â°)\", fontsize=16)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "color-section",
            "metadata": {},
            "source": [
                "## 7. é¢œè‰²å¢å¼º\n",
                "\n",
                "### 7.1 ColorJitter - é¢œè‰²æŠ–åŠ¨"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "color-jitter",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰é¢œè‰²æŠ–åŠ¨\n",
                "# brightness: äº®åº¦è°ƒæ•´èŒƒå›´ [1-0.3, 1+0.3] = [0.7, 1.3]\n",
                "# contrast: å¯¹æ¯”åº¦è°ƒæ•´èŒƒå›´\n",
                "# saturation: é¥±å’Œåº¦è°ƒæ•´èŒƒå›´\n",
                "# hue: è‰²è°ƒè°ƒæ•´èŒƒå›´ [-0.1, 0.1]\n",
                "color_jitter = transforms.ColorJitter(\n",
                "    brightness=0.3,\n",
                "    contrast=0.3,\n",
                "    saturation=0.3,\n",
                "    hue=0.1\n",
                ")\n",
                "\n",
                "# å¤šæ¬¡åº”ç”¨ï¼Œè§‚å¯Ÿæ•ˆæœ\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i in range(6):\n",
                "    jittered_img = color_jitter(img_pil)\n",
                "    axes[i].imshow(jittered_img)\n",
                "    axes[i].set_title(f\"é¢œè‰²æŠ–åŠ¨ #{i+1}\")\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle(\"ColorJitter - éšæœºè°ƒæ•´äº®åº¦/å¯¹æ¯”åº¦/é¥±å’Œåº¦/è‰²è°ƒ\", fontsize=16)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "grayscale-section",
            "metadata": {},
            "source": [
                "### 7.2 RandomGrayscale - éšæœºç°åº¦åŒ–"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "random-grayscale",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰éšæœºç°åº¦åŒ–ï¼ˆp=0.5 è¡¨ç¤ºæœ‰ 50% çš„æ¦‚ç‡è½¬ä¸ºç°åº¦å›¾ï¼‰\n",
                "grayscale = transforms.RandomGrayscale(p=1.0)  # p=1.0 è¡¨ç¤ºå¿…å®šè½¬ä¸ºç°åº¦ï¼ˆä¸ºäº†æ¼”ç¤ºï¼‰\n",
                "\n",
                "# æ‰§è¡Œç°åº¦åŒ–\n",
                "grayscale_img = grayscale(img_pil)\n",
                "\n",
                "# æ˜¾ç¤ºå¯¹æ¯”\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
                "axes[0].imshow(img_pil)\n",
                "axes[0].set_title(\"åŸå§‹å½©è‰²å›¾ç‰‡\")\n",
                "axes[0].axis('off')\n",
                "\n",
                "axes[1].imshow(grayscale_img)\n",
                "axes[1].set_title(\"ç°åº¦å›¾\")\n",
                "axes[1].axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "compose-section",
            "metadata": {},
            "source": [
                "## 8. ç»„åˆå˜æ¢ - Compose\n",
                "\n",
                "åœ¨å®é™…è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬é€šå¸¸éœ€è¦ç»„åˆå¤šä¸ªå˜æ¢æ“ä½œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "compose",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰è®­ç»ƒé›†çš„æ•°æ®å¢å¼ºæµç¨‹\n",
                "train_transform = transforms.Compose([\n",
                "    transforms.Resize((256, 256)),              # 1. ç»Ÿä¸€è°ƒæ•´ä¸º 256x256\n",
                "    transforms.RandomCrop((224, 224)),          # 2. éšæœºè£å‰ªä¸º 224x224\n",
                "    transforms.RandomHorizontalFlip(p=0.5),     # 3. 50% æ¦‚ç‡æ°´å¹³ç¿»è½¬\n",
                "    transforms.RandomRotation(degrees=15),      # 4. éšæœºæ—‹è½¬ Â±15Â°\n",
                "    transforms.ColorJitter(                     # 5. é¢œè‰²æŠ–åŠ¨\n",
                "        brightness=0.2,\n",
                "        contrast=0.2,\n",
                "        saturation=0.2,\n",
                "        hue=0.1\n",
                "    ),\n",
                "    transforms.ToTensor(),                      # 6. è½¬ä¸º Tensor\n",
                "    transforms.Normalize(                       # 7. æ ‡å‡†åŒ–\n",
                "        mean=[0.485, 0.456, 0.406],\n",
                "        std=[0.229, 0.224, 0.225]\n",
                "    )\n",
                "])\n",
                "\n",
                "# å®šä¹‰éªŒè¯é›†çš„æ•°æ®å¢å¼ºæµç¨‹ï¼ˆé€šå¸¸ä¸åšéšæœºæ“ä½œï¼‰\n",
                "val_transform = transforms.Compose([\n",
                "    transforms.Resize((256, 256)),\n",
                "    transforms.CenterCrop((224, 224)),          # éªŒè¯é›†ç”¨ä¸­å¿ƒè£å‰ªï¼Œè€Œééšæœºè£å‰ª\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(\n",
                "        mean=[0.485, 0.456, 0.406],\n",
                "        std=[0.229, 0.224, 0.225]\n",
                "    )\n",
                "])\n",
                "\n",
                "print(\"âœ… è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„å˜æ¢æµç¨‹å·²å®šä¹‰ï¼\")\n",
                "print(f\"\\nè®­ç»ƒé›†å˜æ¢æµç¨‹ï¼š\\n{train_transform}\")\n",
                "print(f\"\\néªŒè¯é›†å˜æ¢æµç¨‹ï¼š\\n{val_transform}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "compose-demo-section",
            "metadata": {},
            "source": [
                "### 8.1 å¯è§†åŒ–ç»„åˆå˜æ¢æ•ˆæœ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "compose-demo",
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰ä¸€ä¸ªä¸åŒ…å« Normalize çš„å˜æ¢ï¼ˆä¾¿äºå¯è§†åŒ–ï¼‰\n",
                "visual_transform = transforms.Compose([\n",
                "    transforms.Resize((256, 256)),\n",
                "    transforms.RandomCrop((224, 224)),\n",
                "    transforms.RandomHorizontalFlip(p=0.5),\n",
                "    transforms.RandomRotation(degrees=15),\n",
                "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
                "])\n",
                "\n",
                "# åº”ç”¨å¤šæ¬¡ï¼Œå±•ç¤ºå¢å¼ºæ•ˆæœ\n",
                "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
                "axes = axes.flatten()\n",
                "\n",
                "# ç¬¬ä¸€å¼ æ˜¾ç¤ºåŸå›¾\n",
                "axes[0].imshow(img_pil)\n",
                "axes[0].set_title(\"åŸå§‹å›¾ç‰‡\", fontsize=12, fontweight='bold')\n",
                "axes[0].axis('off')\n",
                "\n",
                "# å…¶ä½™ 11 å¼ æ˜¾ç¤ºå¢å¼ºåçš„æ•ˆæœ\n",
                "for i in range(1, 12):\n",
                "    augmented_img = visual_transform(img_pil)\n",
                "    axes[i].imshow(augmented_img)\n",
                "    axes[i].set_title(f\"å¢å¼º #{i}\", fontsize=12)\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle(\"ç»„åˆå˜æ¢æ•ˆæœ - æ¯æ¬¡éƒ½ä¸åŒï¼\", fontsize=18, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tensorboard-section",
            "metadata": {},
            "source": [
                "## 9. ä¿å­˜åˆ° TensorBoard\n",
                "\n",
                "å°†å˜æ¢åçš„å›¾ç‰‡ä¿å­˜åˆ° TensorBoard ä¸­æŸ¥çœ‹"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "tensorboard",
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ›å»º TensorBoard è®°å½•å™¨\n",
                "writer = SummaryWriter(\"logs/transforms\")\n",
                "\n",
                "# è®°å½•åŸå§‹å›¾ç‰‡\n",
                "img_array = np.array(img_pil)\n",
                "writer.add_image(\"åŸå§‹å›¾ç‰‡\", img_array, global_step=0, dataformats='HWC')\n",
                "\n",
                "# è®°å½•å¤šä¸ªå¢å¼ºåçš„å›¾ç‰‡\n",
                "for i in range(10):\n",
                "    augmented_img = visual_transform(img_pil)\n",
                "    augmented_array = np.array(augmented_img)\n",
                "    writer.add_image(\"æ•°æ®å¢å¼º\", augmented_array, global_step=i+1, dataformats='HWC')\n",
                "\n",
                "writer.close()\n",
                "print(\"âœ… å›¾ç‰‡å·²ä¿å­˜åˆ° TensorBoardï¼\")\n",
                "print(\"ğŸ“Š è¿è¡Œå‘½ä»¤æŸ¥çœ‹: tensorboard --logdir=logs/transforms\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary-section",
            "metadata": {},
            "source": [
                "## 10. æ€»ç»“\n",
                "\n",
                "### ğŸ“Œ å¸¸ç”¨å˜æ¢é€ŸæŸ¥è¡¨\n",
                "\n",
                "| å˜æ¢åç§° | åŠŸèƒ½ | å¸¸ç”¨å‚æ•° | ä½¿ç”¨åœºæ™¯ |\n",
                "|---------|------|---------|----------|\n",
                "| `ToTensor()` | è½¬ä¸º Tensor | æ—  | **å¿…é¡»ä½¿ç”¨** |\n",
                "| `Normalize()` | æ ‡å‡†åŒ– | mean, std | **å¿…é¡»ä½¿ç”¨**ï¼ˆè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ï¼‰ |\n",
                "| `Resize()` | è°ƒæ•´å¤§å° | size | ç»Ÿä¸€å›¾ç‰‡å°ºå¯¸ |\n",
                "| `RandomCrop()` | éšæœºè£å‰ª | size | **è®­ç»ƒé›†**æ•°æ®å¢å¼º |\n",
                "| `CenterCrop()` | ä¸­å¿ƒè£å‰ª | size | **éªŒè¯é›†**å›ºå®šè£å‰ª |\n",
                "| `RandomHorizontalFlip()` | éšæœºæ°´å¹³ç¿»è½¬ | p=0.5 | **è®­ç»ƒé›†**å¢å¼ºï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰ |\n",
                "| `RandomVerticalFlip()` | éšæœºå‚ç›´ç¿»è½¬ | p=0.5 | åŒ»å­¦å½±åƒã€å«æ˜Ÿå›¾åƒ |\n",
                "| `RandomRotation()` | éšæœºæ—‹è½¬ | degrees | **è®­ç»ƒé›†**å¢å¼º |\n",
                "| `ColorJitter()` | é¢œè‰²æŠ–åŠ¨ | brightness, contrast, saturation, hue | **è®­ç»ƒé›†**å¢å¼º |\n",
                "| `RandomGrayscale()` | éšæœºç°åº¦åŒ– | p | ç‰¹æ®Šåœºæ™¯å¢å¼º |\n",
                "| `Compose()` | ç»„åˆå¤šä¸ªå˜æ¢ | list of transforms | **ç»„åˆå¤šä¸ªæ“ä½œ** |\n",
                "\n",
                "### ğŸ’¡ æœ€ä½³å®è·µ\n",
                "\n",
                "1. **è®­ç»ƒé›†**ï¼šä½¿ç”¨ä¸°å¯Œçš„æ•°æ®å¢å¼ºï¼ˆéšæœºè£å‰ªã€ç¿»è½¬ã€æ—‹è½¬ã€é¢œè‰²æŠ–åŠ¨ç­‰ï¼‰\n",
                "2. **éªŒè¯é›†/æµ‹è¯•é›†**ï¼šåªåšåŸºç¡€å˜æ¢ï¼ˆResize â†’ CenterCrop â†’ ToTensor â†’ Normalizeï¼‰\n",
                "3. **Normalize çš„ mean å’Œ std**ï¼š\n",
                "   - ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ ImageNet çš„å‚æ•°\n",
                "   - è‡ªå·±è®­ç»ƒæ—¶ï¼Œå¯ä»¥è®¡ç®—è‡ªå·±æ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®\n",
                "4. **å˜æ¢é¡ºåºå¾ˆé‡è¦**ï¼š\n",
                "   - å…ˆåšå‡ ä½•å˜æ¢ï¼ˆè£å‰ªã€ç¿»è½¬ã€æ—‹è½¬ï¼‰\n",
                "   - å†åšé¢œè‰²å˜æ¢ï¼ˆColorJitterï¼‰\n",
                "   - æœ€åè½¬ä¸º Tensor å¹¶æ ‡å‡†åŒ–\n",
                "\n",
                "### ğŸ¯ ä¸‹ä¸€æ­¥å­¦ä¹ \n",
                "\n",
                "- å­¦ä¹  `DataLoader` æ‰¹é‡åŠ è½½æ•°æ®\n",
                "- å°†è‡ªå®šä¹‰ Dataset ä¸ transforms ç»“åˆä½¿ç”¨\n",
                "- æ„å»ºç¬¬ä¸€ä¸ªåˆ†ç±»æ¨¡å‹å¹¶è®­ç»ƒ"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pytorch_basics",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.25"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}