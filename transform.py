import torch
import cv2
import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms
from torch.utils.tensorboard import SummaryWriter

# ================= 0. å…¨å±€è®¾ç½® =================
# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å… matplotlib æ˜¾ç¤ºä¸­æ–‡ä¹±ç ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei']  # Windowså¸¸ç”¨ SimHeiï¼ŒMacå¯ç”¨ Arial Unicode MS
plt.rcParams['axes.unicode_minus'] = False    # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# ================= 1. è¾…åŠ©å‡½æ•°å®šä¹‰ =================
def load_image(path):
    """è¯»å–å›¾ç‰‡å¹¶è¿›è¡ŒåŸºç¡€æ£€æŸ¥"""
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å›¾ç‰‡: {path}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
    
    # å§‹ç»ˆæ¨èä½¿ç”¨ PIL è¯»å–ï¼Œå› ä¸º torchvision é»˜è®¤å°±æ˜¯é’ˆå¯¹ PIL è®¾è®¡çš„
    img = Image.open(path)
    print(f"âœ… å›¾ç‰‡è¯»å–æˆåŠŸ | å°ºå¯¸: {img.size} (å®½xé«˜) | æ¨¡å¼: {img.mode}")
    return img

def plot_compare(orig_img, trans_imgs, title_prefix="Transform"):
    """
    é€šç”¨ç»˜å›¾å‡½æ•°ï¼šå¯¹æ¯”åŸå›¾å’Œå˜æ¢åçš„å›¾ç‰‡
    :param orig_img: åŸå§‹ PIL å›¾ç‰‡
    :param trans_imgs: å˜æ¢åçš„å›¾ç‰‡åˆ—è¡¨ (list of PIL Images)
    :param title_prefix: æ ‡é¢˜å‰ç¼€
    """
    count = len(trans_imgs) + 1
    # åŠ¨æ€è®¡ç®—å­å›¾å¸ƒå±€ï¼Œæœ€å¤šä¸€è¡Œæ”¾ 4 å¼ 
    cols = min(count, 4)
    rows = (count - 1) // 4 + 1
    
    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))
    
    # å¤„ç† axes ä¸ºå•ä¸ªå¯¹è±¡æˆ–ä¸€ç»´æ•°ç»„çš„æƒ…å†µï¼Œç»Ÿä¸€è½¬ä¸ºåˆ—è¡¨å¤„ç†
    if isinstance(axes, np.ndarray):
        axes = axes.flatten()
    else:
        axes = [axes]

    # 1. ç”»åŸå›¾
    axes[0].imshow(orig_img)
    axes[0].set_title("åŸå§‹å›¾ç‰‡", fontweight='bold')
    axes[0].axis('off')

    # 2. ç”»å˜æ¢å›¾
    for i, img in enumerate(trans_imgs):
        if i + 1 < len(axes):
            axes[i+1].imshow(img)
            axes[i+1].set_title(f"{title_prefix} #{i+1}")
            axes[i+1].axis('off')
    
    # éšè—å¤šä½™çš„ç©ºå­å›¾
    for j in range(count, len(axes)):
        axes[j].axis('off')

    plt.suptitle(f"{title_prefix} æ•ˆæœå±•ç¤º", fontsize=14)
    plt.tight_layout()
    plt.show()

# ================= 2. ä¸»é€»è¾‘ =================

# --- 2.1 å‡†å¤‡æ•°æ® ---
# è¯·ç¡®ä¿æ­¤è·¯å¾„å­˜åœ¨ï¼Œæˆ–è€…ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„å›¾ç‰‡è·¯å¾„
img_path = r'data\train\bees_image\16838648_415acd9e3f.jpg' 
try:
    img_pil = load_image(img_path)
except Exception as e:
    print(e)
    # å¦‚æœæ‰¾ä¸åˆ°å›¾ç‰‡ï¼Œè¿™ä¸€è¡Œä¼šè®©ç¨‹åºå®‰å…¨åœæ­¢ï¼Œæ–¹ä¾¿ä½ å»ä¿®è·¯å¾„
    exit() 

# --- 2.2 åŸºç¡€å˜æ¢åŸç† (Tensor & Normalize) ---
print("\n--- æ­£åœ¨æ¼”ç¤ºåŸºç¡€ Tensor å˜æ¢ ---")

# å®ä¾‹åŒ– ToTensor
to_tensor = transforms.ToTensor()
tensor_img = to_tensor(img_pil)

print(f"Tensor å½¢çŠ¶: {tensor_img.shape}")  # (C, H, W) -> PyTorch æ ¼å¼ (é€šé“, é«˜, å®½)
print(f"Tensor èŒƒå›´: [{tensor_img.min():.3f}, {tensor_img.max():.3f}]") # 0.0 ~ 1.0

# ğŸ”´ éš¾ç‚¹è§£æï¼šä¸ºä»€ä¹ˆè¦ .permute(1, 2, 0)ï¼Ÿ
# PyTorch (æœºå™¨çœ‹) æ ¼å¼: (C, H, W) -> (3, 512, 768)
# Matplotlib (äººçœ¼çœ‹) æ ¼å¼: (H, W, C) -> (512, 768, 3)
# permute å°±æ˜¯è´Ÿè´£æŠŠç»´åº¦æ¬è¿å›å»ï¼Œå¦åˆ™ç”»å›¾ä¼šæŠ¥é”™ã€‚
img_for_plt = tensor_img.permute(1, 2, 0)

# å®šä¹‰æ ‡å‡†åŒ– (ä½¿ç”¨ ImageNet ç»Ÿè®¡å€¼)
# å…¬å¼: output = (input - mean) / std
# ä½œç”¨: æŠŠæ•°æ®æ‹‰å› 0 é™„è¿‘ï¼ŒåŠ é€Ÿç¥ç»ç½‘ç»œæ”¶æ•›
norm_transform = transforms.Normalize(
    mean=[0.485, 0.456, 0.406], 
    std=[0.229, 0.224, 0.225]
)
norm_img = norm_transform(tensor_img)
print(f"æ ‡å‡†åŒ–åèŒƒå›´: [{norm_img.min():.3f}, {norm_img.max():.3f}] (å‡ºç°è´Ÿæ•°æ˜¯æ­£å¸¸çš„)")


# --- 2.3 å¸¸ç”¨å¢å¼ºæ“ä½œå¯è§†åŒ– (å»é™¤äº†å†—ä½™ä»£ç ) ---
print("\n--- æ­£åœ¨æ¼”ç¤ºå•ä¸€å˜æ¢æ•ˆæœ ---")

# ä¸ºäº†å‡å°‘ä»£ç å†—ä½™ï¼Œæˆ‘ä»¬æŠŠå˜æ¢å®šä¹‰åœ¨ä¸€ä¸ªå­—å…¸é‡Œï¼Œå¾ªç¯å±•ç¤º
transforms_dict = {
    "Resize (ç¼©æ”¾)": transforms.Resize((256, 256)),
    "RandomCrop (éšæœºè£å‰ª)": transforms.RandomCrop((200, 200)),
    "RandomRotation (éšæœºæ—‹è½¬)": transforms.RandomRotation(degrees=45),
    "ColorJitter (é¢œè‰²æŠ–åŠ¨)": transforms.ColorJitter(brightness=0.5, contrast=0.5),
    "RandomHorizontalFlip (æ°´å¹³ç¿»è½¬)": transforms.RandomHorizontalFlip(p=1.0) # p=1.0 å¼ºåˆ¶ç¿»è½¬
}

# å¾ªç¯æ¼”ç¤ºæ¯ä¸ªå˜æ¢
# ä¸ºäº†äººçœ¼çœ‹ï¼Œè¿˜æ˜¯åœ¨å¯¹img_pilè¿™ä¸ªåŸææ–™è¿›è¡Œæ“ä½œ
for name, transformer in transforms_dict.items():
    # ç”Ÿæˆ 3 å¼ æ•ˆæœå›¾æ¥è§‚å¯Ÿéšæœºæ€§
    demo_imgs = [transformer(img_pil) for _ in range(3)]
    plot_compare(img_pil, demo_imgs, title_prefix=name)


# --- 2.4 æ ¸å¿ƒï¼šå®Œæ•´çš„ Compose æµæ°´çº¿ ---
print("\n--- æ­£åœ¨æ¼”ç¤ºå®Œæ•´ Compose æµæ°´çº¿ ---")

# ã€è®­ç»ƒé›†ã€‘éœ€è¦â€œæŠ˜è…¾â€å›¾ç‰‡ï¼Œå¢åŠ æ•°æ®å¤šæ ·æ€§
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),              # 1. å…ˆæ”¾å¤§ä¸€ç‚¹
    transforms.RandomCrop((224, 224)),          # 2. éšæœºåˆ‡å‡ºæ ¸å¿ƒåŒºåŸŸ
    transforms.RandomHorizontalFlip(p=0.5),     # 3. éšæœºç¿»è½¬
    transforms.RandomRotation(degrees=15),      # 4. éšæœºæ—‹è½¬
    transforms.ColorJitter(brightness=0.2, contrast=0.2), # 5. é¢œè‰²å¢å¼º
    transforms.ToTensor(),                      # 6. è½¬ Tensor (0-1)
    transforms.Normalize(                       # 7. æ ‡å‡†åŒ– (å˜è´Ÿæ•°)
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225]
    )
])

# ã€éªŒè¯é›†ã€‘å¿…é¡»å›ºå®šï¼Œä¸èƒ½æœ‰éšæœºæ€§
val_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop((224, 224)),          # âš ï¸ æ³¨æ„ï¼šéªŒè¯é›†ç”¨ CenterCrop
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225]
    )
])

print("âœ… è®­ç»ƒ/éªŒè¯æµå®šä¹‰å®Œæˆï¼")


# --- 2.5 åªæœ‰â€œè§†è§‰â€å˜æ¢çš„æµæ°´çº¿ (ç”¨äº TensorBoard å±•ç¤º) ---
# ä¸“é—¨å®šä¹‰ä¸€ä¸ªä¸å¸¦ Normalize çš„ composeï¼Œæ–¹ä¾¿äººç±»è§‚å¯Ÿ
visual_compose = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.3)
    # âŒ ä¸åŠ  ToTensor å’Œ Normalizeï¼Œä¿æŒ PIL æ ¼å¼æ–¹ä¾¿ç”»å›¾
])

# è®°å½•åˆ° TensorBoard
log_dir = "logs/transforms_demo"
writer = SummaryWriter(log_dir)

# è®°å½• 10 å¼ å¢å¼ºåçš„å›¾
print(f"\n--- æ­£åœ¨å†™å…¥ TensorBoard (è·¯å¾„: {log_dir}) ---")
# å…ˆè®°ä¸€å¼ åŸå›¾
writer.add_image("Original", np.array(img_pil), global_step=0, dataformats='HWC')

for i in range(10):
    aug_img = visual_compose(img_pil)
    # æ³¨æ„ï¼šadd_image éœ€è¦ numpy æ•°ç»„æˆ– tensor
    writer.add_image("Augmented_Showcase", np.array(aug_img), global_step=i+1, dataformats='HWC')

writer.close()
print(f"âœ… å®Œæˆï¼è¯·åœ¨ç»ˆç«¯è¿è¡Œ: tensorboard --logdir={log_dir} æŸ¥çœ‹ç»“æœ")